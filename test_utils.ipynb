{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc61c61c-fda8-4ef6-a6ac-51d507f7bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "from data_loader import label_to_text\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "matplotlib.use('Agg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e27148b9-c86d-4b0a-81d2-fcb263760e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(preds, labels):\n",
    "    return (preds == labels).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8826231-b3f0-47d0-bf23-b543442daca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device, label_to_text_map):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, input_ids, attention_mask, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            image_feature_vector, text_feature_vector, image_cls, text_cls,  (first_expert_outputs, second_expert_outputs), (first_gating_output, second_gating_output) = model(images, input_ids, attention_mask)\n",
    "            _, preds = torch.max(image_cls, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    accuracy = sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels)\n",
    "    \n",
    "    print(\"\\n预测结果:\")\n",
    "    print_output_distribution(image_cls)\n",
    "    for pred, label in zip(all_preds[:10], all_labels[:10]):  # 只打印前10个结果\n",
    "        pred_text = label_to_text_map[pred]\n",
    "        true_text = label_to_text_map[label]\n",
    "        print(f\"预测: {pred_text}, 实际: {true_text}\")\n",
    "    \n",
    "    print(f\"\\n准确率: {accuracy:.4f}\")\n",
    "    visualize_expert_attention(model, dataloader, device, num_experts=10)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29cd3e2b-626b-451b-bcb5-c98e377aab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataloader, device, label_to_text_map):\n",
    "    model.eval()\n",
    "    images, input_ids, attention_mask, labels = next(iter(dataloader))\n",
    "    images = images.to(device)\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    # 设置中文字体\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体\n",
    "    plt.rcParams['axes.unicode_minus'] = False  # 正确显示负号\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_feature_vector, text_feature_vector, image_cls, text_cls,  (first_expert_outputs, second_expert_outputs), (first_gating_output, second_gating_output) = model(images, input_ids, attention_mask)\n",
    "        _, preds = torch.max(image_cls, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(images):\n",
    "            img = images[i].cpu().numpy()\n",
    "            if img.shape[0] == 3:  # 如果是RGB图像（CIFAR10）\n",
    "                img = img.transpose(1, 2, 0)  # 将通道维度从(3, 32, 32)转换为(32, 32, 3)\n",
    "            else:  # 如果是灰度图像（FashionMNIST）\n",
    "                img = img.squeeze()\n",
    "            \n",
    "            # 确保图像数据在0-1范围内\n",
    "            img = (img - img.min()) / (img.max() - img.min())\n",
    "            \n",
    "            ax.imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
    "            pred_text = label_to_text_map[preds[i].item()]\n",
    "            true_text = label_to_text_map[labels[i].item()]\n",
    "            ax.set_title(f'Pred: {pred_text}\\nTrue: {true_text}', fontsize=10)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('predictions.png')\n",
    "    plt.close()  # 关闭图形以释放内存\n",
    "\n",
    "    print(\"可视化结果已保存到 'predictions.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b20f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output_distribution(outputs):\n",
    "    probs = F.softmax(outputs, dim=1)\n",
    "    avg_probs = probs.mean(dim=0)\n",
    "    for i, prob in enumerate(avg_probs):\n",
    "        print(f\"Class {i}: {prob.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bedbd84-4125-400e-a067-9c2e0f01db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_expert_attention(model, dataloader, device, num_experts=10):\n",
    "    model.eval()\n",
    "    images, input_ids, attention_mask, labels = next(iter(dataloader))\n",
    "    images = images.to(device)\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_feature_vector, text_feature_vector, image_cls, text_cls, \\\n",
    "        (first_expert_outputs, second_expert_outputs), (first_gating_output, second_gating_output) = \\\n",
    "            model(images, input_ids, attention_mask)\n",
    "    \n",
    "    # 设置中文字体\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    # 可视化图像专家注意力\n",
    "    batch_size = images.size(0)\n",
    "    for batch_idx in range(min(3, batch_size)):  # 只显示前3个样本\n",
    "        fig, axes = plt.subplots(3, num_experts, figsize=(20, 12))\n",
    "        fig.suptitle(f'样本 {batch_idx + 1} 的专家注意力分布', fontsize=16)\n",
    "        \n",
    "        # 显示原图\n",
    "        img = images[batch_idx].cpu().numpy()\n",
    "        if img.shape[0] == 3:  # RGB图像\n",
    "            img = img.transpose(1, 2, 0)\n",
    "        else:  # 灰度图像\n",
    "            img = img.squeeze()\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        for expert_idx in range(num_experts):\n",
    "            axes[0, expert_idx].imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
    "            axes[0, expert_idx].set_title('原图')\n",
    "            axes[0, expert_idx].axis('off')\n",
    "        \n",
    "        # 第一层MoE的专家注意力\n",
    "        for expert_idx in range(num_experts):\n",
    "            expert_output = first_expert_outputs[expert_idx][batch_idx]\n",
    "            attention_map = expert_output.norm(dim=-1).cpu().numpy()\n",
    "            attention_map = attention_map.reshape(8, 8)  # 假设patch size为4，32x32图像会得到8x8的注意力图\n",
    "            \n",
    "            axes[1, expert_idx].imshow(attention_map, cmap='hot')\n",
    "            axes[1, expert_idx].set_title(f'专家 {expert_idx}\\n第一层')\n",
    "            axes[1, expert_idx].axis('off')\n",
    "        \n",
    "        # 第二层MoE的专家注意力\n",
    "        for expert_idx in range(num_experts):\n",
    "            expert_output = second_expert_outputs[expert_idx][batch_idx]\n",
    "            attention_map = expert_output.norm(dim=-1).cpu().numpy()\n",
    "            attention_map = attention_map.reshape(8, 8)\n",
    "            \n",
    "            axes[2, expert_idx].imshow(attention_map, cmap='hot')\n",
    "            axes[2, expert_idx].set_title(f'专家 {expert_idx}\\n第二层')\n",
    "            axes[2, expert_idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'expert_attention_sample_{batch_idx}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 可视化门控网络的分配情况\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 第一层MoE的门控分布\n",
    "    plt.subplot(1, 2, 1)\n",
    "    gating_weights = first_gating_output[0].cpu().numpy()\n",
    "    plt.imshow(gating_weights, aspect='auto', cmap='viridis')\n",
    "    plt.title('第一层MoE门控分布')\n",
    "    plt.xlabel('专家')\n",
    "    plt.ylabel('Token')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 第二层MoE的门控分布\n",
    "    plt.subplot(1, 2, 2)\n",
    "    gating_weights = second_gating_output[0].cpu().numpy()\n",
    "    plt.imshow(gating_weights, aspect='auto', cmap='viridis')\n",
    "    plt.title('第二层MoE门控分布')\n",
    "    plt.xlabel('专家')\n",
    "    plt.ylabel('Token')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gating_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"专家注意力可视化结果已保存\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
