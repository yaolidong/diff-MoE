{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff559abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from positional_encoder import positional_encoding\n",
    "import mHselfAttention\n",
    "from NoisyTopkRouter import NoisyTopkRouter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SparseMoE(nn.Module):\n",
    "    def __init__(self, n_embd=512, top_k=2, num_experts=10):\n",
    "        super(SparseMoE, self).__init__()\n",
    "        self.experts = nn.ModuleList([mHselfAttention.Expert(n_embd) for _ in range(num_experts)])\n",
    "        self.router = NoisyTopkRouter(n_embd, top_k, num_experts)\n",
    "        self.top_k = top_k\n",
    "        self.num_experts = num_experts\n",
    "\n",
    "    def forward(self, x):\n",
    "        gating_output, indices = self.router(x)\n",
    "        final_output = torch.zeros_like(x)\n",
    "        expert_outputs = [torch.zeros_like(x) for _ in range(self.num_experts)]\n",
    "\n",
    "        flat_x = x.view(-1, x.size(-1))\n",
    "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
    "\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            expert_mask = (indices == i).any(dim=-1)\n",
    "            flat_mask = expert_mask.view(-1)\n",
    "\n",
    "            if flat_mask.any():\n",
    "                expert_input = flat_x[flat_mask]\n",
    "                expert_output = expert(expert_input)\n",
    "\n",
    "                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)\n",
    "                weighted_output = expert_output * gating_scores\n",
    "\n",
    "                final_output[expert_mask] += weighted_output.squeeze(1)\n",
    "                expert_outputs[i][expert_mask] = weighted_output.squeeze(1)\n",
    "\n",
    "        return final_output, expert_outputs, gating_output\n",
    "\n",
    "\n",
    "class ImageMoE(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=4, in_channels=3, embed_dim=1024, num_experts=10, top_k=2):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.in_channels = in_channels\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.patch_dim = patch_size * patch_size * in_channels\n",
    "        self.output_dim = embed_dim\n",
    "        self.head_size = embed_dim // 8\n",
    "        self.num_experts = num_experts\n",
    "\n",
    "        self.patch_embeddings = nn.Linear(self.patch_dim, embed_dim)\n",
    "        self.positional_encoding = positional_encoding(128, self.num_patches, embed_dim)\n",
    "        self.sa = mHselfAttention.MultiHeadAttention(seq_len=self.num_patches, n_embd=embed_dim, n_head=8, head_size=self.head_size, dropout=0.1)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches, embed_dim))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.ln3 = nn.LayerNorm(embed_dim)\n",
    "        self.first_moe = SparseMoE(embed_dim, top_k, num_experts)\n",
    "        self.second_moe = SparseMoE(embed_dim, top_k, num_experts)\n",
    "        self.classification = nn.Linear(embed_dim, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        \n",
    "        if c == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "            c = 3\n",
    "        \n",
    "        if h != self.img_size or w != self.img_size:\n",
    "            x = nn.functional.interpolate(x, size=(self.img_size, self.img_size), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
    "        x = x.contiguous().view(b, c, -1, self.patch_size * self.patch_size)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous().view(b, -1, self.patch_dim)\n",
    "        \n",
    "        x = self.patch_embeddings(x)\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.pos_embedding.to(x.device)\n",
    "        x = self.dropout(x)\n",
    "        first_output, first_expert_outputs, first_gating_output = self.first_moe(self.ln2(x))\n",
    "        second_output, second_expert_outputs, second_gating_output = self.second_moe(self.ln3(x))\n",
    "        feature_vector = second_output.mean(dim=1)\n",
    "        cls = self.classification(feature_vector)\n",
    "\n",
    "        return first_output, second_output, feature_vector, cls, (first_expert_outputs, second_expert_outputs), (first_gating_output, second_gating_output)\n",
    "\n",
    "class TextMoE(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_length=16, embed_dim=1024, num_experts=10, top_k=2):\n",
    "        super().__init__()\n",
    "        self.head_size = embed_dim//8\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = positional_encoding(128, seq_length, embed_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_length, embed_dim))\n",
    "        self.sa = mHselfAttention.MultiHeadAttention(seq_len=seq_length, n_embd=embed_dim, n_head=8, head_size=self.head_size, dropout=0.1)\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.ln3 = nn.LayerNorm(embed_dim)\n",
    "        self.first_moe = SparseMoE(embed_dim, top_k, num_experts)\n",
    "        self.second_moe = SparseMoE(embed_dim, top_k, num_experts)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classification = nn.Linear(embed_dim, 10)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):  \n",
    "        b = input_ids.shape[0]\n",
    "        # 词嵌入[128,16,128]\n",
    "        x = self.embedding(input_ids)\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        # 添加位置编码[128,16,128]\n",
    "        x = x + self.pos_embedding.to(x.device)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        first_output, _, _ = self.first_moe(self.ln2(x))\n",
    "        second_output, _, _ = self.second_moe(self.ln3(x))\n",
    "        feature_vector = second_output.mean(dim=1)  # 取平均值作为特征向量\n",
    "        cls = self.classification(feature_vector)\n",
    "        return first_output, second_output, feature_vector, cls\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
